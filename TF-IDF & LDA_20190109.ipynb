{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Obama_2016.txt', 'r') as f:\n",
    "    doc = f.read()\n",
    "    \n",
    "# 읽고자하는 txt파일이 정확히 Jupyter File이 있는 폴더에 \"함께\" 들어있어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"anuary 12, 2016\\nThank you. Mr. Speaker, Mr. Vice President, Members of Congress, my fellow Americans: Tonight marks the eighth year that I've come here to report on the State of the Union. And for this final one, I'm going to try to make it a little shorter. I know some of you are antsy to get back to Iowa. [Laughter] I've been there. I'll be shaking hands afterwards if you want some tips. [Laughter]\\n\\nNow, I understand that because it's an election season, expectations for what we will achieve t\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anuary',\n",
       " '12',\n",
       " ',',\n",
       " '2016',\n",
       " 'Thank',\n",
       " 'you',\n",
       " '.',\n",
       " 'Mr.',\n",
       " 'Speaker',\n",
       " ',',\n",
       " 'Mr.',\n",
       " 'Vice',\n",
       " 'President',\n",
       " ',',\n",
       " 'Members',\n",
       " 'of',\n",
       " 'Congress',\n",
       " ',',\n",
       " 'my',\n",
       " 'fellow',\n",
       " 'Americans',\n",
       " ':',\n",
       " 'Tonight',\n",
       " 'marks',\n",
       " 'the',\n",
       " 'eighth',\n",
       " 'year',\n",
       " 'that',\n",
       " 'I',\n",
       " \"'ve\",\n",
       " 'come',\n",
       " 'here',\n",
       " 'to',\n",
       " 'report',\n",
       " 'on',\n",
       " 'the',\n",
       " 'State',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Union',\n",
       " '.',\n",
       " 'And',\n",
       " 'for',\n",
       " 'this',\n",
       " 'final',\n",
       " 'one',\n",
       " ',',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'going']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing\n",
    "\n",
    "doc_tokens = nltk.word_tokenize(doc)\n",
    "doc_tokens[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anuary',\n",
       " '12',\n",
       " ',',\n",
       " '2016',\n",
       " 'Thank',\n",
       " 'you',\n",
       " '.',\n",
       " 'Mr.',\n",
       " 'Speaker',\n",
       " ',',\n",
       " 'Mr.',\n",
       " 'Vice',\n",
       " 'President',\n",
       " ',',\n",
       " 'Members',\n",
       " 'of',\n",
       " 'Congress',\n",
       " ',',\n",
       " 'my',\n",
       " 'fellow',\n",
       " 'Americans',\n",
       " ':',\n",
       " 'Tonight',\n",
       " 'mark',\n",
       " 'the',\n",
       " 'eighth',\n",
       " 'year',\n",
       " 'that',\n",
       " 'I',\n",
       " \"'ve\",\n",
       " 'come',\n",
       " 'here',\n",
       " 'to',\n",
       " 'report',\n",
       " 'on',\n",
       " 'the',\n",
       " 'State',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Union',\n",
       " '.',\n",
       " 'And',\n",
       " 'for',\n",
       " 'this',\n",
       " 'final',\n",
       " 'one',\n",
       " ',',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'going']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatizing\n",
    "\n",
    "doc_lemma = []\n",
    "lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "for token in doc_tokens:\n",
    "    doc_lemma.append(lemma.lemmatize(token))\n",
    "doc_lemma[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('anuary', 'JJ'),\n",
       " ('12', 'CD'),\n",
       " (',', ','),\n",
       " ('2016', 'CD'),\n",
       " ('Thank', 'NNP'),\n",
       " ('you', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Speaker', 'NNP'),\n",
       " (',', ','),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Vice', 'NNP'),\n",
       " ('President', 'NNP'),\n",
       " (',', ','),\n",
       " ('Members', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Congress', 'NNP'),\n",
       " (',', ','),\n",
       " ('my', 'PRP$'),\n",
       " ('fellow', 'JJ')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_lemma_tagged = nltk.pos_tag(doc_lemma)\n",
    "doc_lemma_tagged[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anuary',\n",
       " '2016',\n",
       " 'Thank',\n",
       " 'Speaker',\n",
       " 'Vice',\n",
       " 'President',\n",
       " 'Members',\n",
       " 'Congress',\n",
       " 'fellow',\n",
       " 'Americans',\n",
       " 'Tonight',\n",
       " 'mark',\n",
       " 'eighth',\n",
       " 'year',\n",
       " 'come',\n",
       " 'report',\n",
       " 'State',\n",
       " 'Union',\n",
       " 'final',\n",
       " 'going']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing Stop Words\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update([',', '.', '?', '!', ':', ';', '[', ']'])\n",
    "doc_filtered = [word for word in doc_lemma if word not in stop_words and len(word) > 3]\n",
    "doc_filtered[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a custom corpus\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "import gensim\n",
    "\n",
    "import os\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "corpusdir = '3M CO_2011-2016/'\n",
    "if not os.path.isdir(corpusdir):\n",
    "    os.mkdir(corpusdir)\n",
    "    \n",
    "corpus = ['3M_2011.txt', '3M_2012.txt', '3M_2013.txt', '3M_2014.txt', '3M_2015.txt', '3M_2016.txt' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in corpus:\n",
    "    doc_tokens = nltk.word_tokenize(doc)\n",
    "    \n",
    "doc_lemma = []\n",
    "lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "for token in doc_tokens:\n",
    "    doc_lemma.append(lemma.lemmatize(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update([',', '.', '?', '!', ':', ';', '[', ']'])\n",
    "filtered_doc = [word for word in doc_lemma if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'yield' outside function (<ipython-input-50-07ae1c76855a>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-50-07ae1c76855a>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    yield{\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'yield' outside function\n"
     ]
    }
   ],
   "source": [
    "# p. 64 'Applied Text Analysis with Python'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
